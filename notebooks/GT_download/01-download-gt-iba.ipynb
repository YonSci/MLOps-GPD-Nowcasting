{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Google Trends data using Institute of Business Administration (IBA), Pakistan keywords\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries/modules\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq(hl='en-US', tz=360, timeout=(40,25))\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the keyword dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BISP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ehsaas program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>House Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Car Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cinema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Weddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cigarette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hotels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fast Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>House for sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FMCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Textile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Economy News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Business News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>World News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Newspapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mehngai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>deficit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>elections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>economic growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>subsidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>current account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>protest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>stock market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_name\n",
       "0    Economic crisis\n",
       "1             Crisis\n",
       "2          Recession\n",
       "3   Financial crisis\n",
       "4          Inflation\n",
       "5       Unemployment\n",
       "6               BISP\n",
       "7     ehsaas program\n",
       "8              USAID\n",
       "9             Credit\n",
       "10              Loan\n",
       "11          Interest\n",
       "12        House Loan\n",
       "13          Car Loan\n",
       "14              Food\n",
       "15            Cinema\n",
       "16              Cars\n",
       "17          Birthday\n",
       "18            Travel\n",
       "19          Weddings\n",
       "20           Fitness\n",
       "21         Cigarette\n",
       "22           Tourism\n",
       "23            Hotels\n",
       "24         Fast Food\n",
       "25    House for sale\n",
       "26      Construction\n",
       "27        Investment\n",
       "28              Jobs\n",
       "29       Agriculture\n",
       "30              FMCG\n",
       "31          Aviation\n",
       "32     Manufacturing\n",
       "33           Textile\n",
       "34      Economy News\n",
       "35     Business News\n",
       "36        World News\n",
       "37          Politics\n",
       "38        Newspapers\n",
       "39           mehngai\n",
       "40       Real estate\n",
       "41           deficit\n",
       "42         elections\n",
       "43        parliament\n",
       "44             taxes\n",
       "45        government\n",
       "46            budget\n",
       "47   economic growth\n",
       "48           subsidy\n",
       "49   current account\n",
       "50             trade\n",
       "51           protest\n",
       "52      stock market\n",
       "53           revenue\n",
       "54               LSM\n",
       "55                M0\n",
       "56               PSB\n",
       "57               CPI"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_IBA = pd.read_excel('data/catagory_name_IBA.xlsx')\n",
    "df_cat_IBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the keywords and create a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Economic crisis',\n",
       " 'Crisis',\n",
       " 'Recession',\n",
       " 'Financial crisis',\n",
       " 'Inflation',\n",
       " 'Unemployment',\n",
       " 'BISP',\n",
       " 'ehsaas program',\n",
       " 'USAID',\n",
       " 'Credit',\n",
       " 'Loan',\n",
       " 'Interest',\n",
       " 'House Loan',\n",
       " 'Car Loan',\n",
       " 'Food',\n",
       " 'Cinema',\n",
       " 'Cars',\n",
       " 'Birthday',\n",
       " 'Travel',\n",
       " 'Weddings',\n",
       " 'Fitness',\n",
       " 'Cigarette',\n",
       " 'Tourism',\n",
       " 'Hotels',\n",
       " 'Fast Food',\n",
       " 'House for sale',\n",
       " 'Construction',\n",
       " 'Investment',\n",
       " 'Jobs',\n",
       " 'Agriculture',\n",
       " 'FMCG',\n",
       " 'Aviation',\n",
       " 'Manufacturing',\n",
       " 'Textile',\n",
       " 'Economy News',\n",
       " 'Business News',\n",
       " 'World News',\n",
       " 'Politics',\n",
       " 'Newspapers',\n",
       " 'mehngai',\n",
       " 'Real estate',\n",
       " 'deficit',\n",
       " 'elections',\n",
       " 'parliament',\n",
       " 'taxes',\n",
       " 'government',\n",
       " 'budget',\n",
       " 'economic growth',\n",
       " 'subsidy',\n",
       " 'current account',\n",
       " 'trade',\n",
       " 'protest',\n",
       " 'stock market',\n",
       " 'revenue',\n",
       " 'LSM',\n",
       " 'M0',\n",
       " 'PSB',\n",
       " 'CPI']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iba_category_name = df_cat_IBA[\"category_name\"].values.tolist()\n",
    "iba_category_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = list(set(iba_category_name))\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the chunk size and split the list into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 15\n",
    "\n",
    "# Split the list into chunks\n",
    "chunks = [keywords[i:i + chunk_size] for i in range(0, len(keywords), chunk_size)]\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name each chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name each chunk as chunk_i starting from 1\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    globals()[f'chunks{i}'] = chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function fetches the Google Trend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_trends_in_batches(chunks,\n",
    "                            batch_size=1,\n",
    "                            cat=0, \n",
    "                            timeframe='2004-01-01 2024-03-31', \n",
    "                            geo='ZA', \n",
    "                            gprop=''):\n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, timeout=(30, 25))\n",
    "    \n",
    "    all_data = []\n",
    "    num_batches = -(-len(chunks) // batch_size)  # Calculate number of batches\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        \n",
    "        batch_keywords = chunks[start_idx:end_idx]\n",
    "        \n",
    "        pytrends.build_payload(batch_keywords, cat=cat, \n",
    "                               timeframe=timeframe,\n",
    "                               geo=geo, \n",
    "                               gprop=gprop)\n",
    "        data = pytrends.interest_over_time()\n",
    "        \n",
    "        all_data.append(data)\n",
    "\n",
    "    combined_data = pd.concat(all_data, axis=1)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store combined dataframes in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(chunks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     combined_data_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_data\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_trends_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mcat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2004-01-01 2024-03-31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mgeo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mgprop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mlen\u001b[39m(combined_data_dict)\n",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m, in \u001b[0;36mfetch_trends_in_batches\u001b[1;34m(chunks, batch_size, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[0;32m     17\u001b[0m     batch_keywords \u001b[38;5;241m=\u001b[39m chunks[start_idx:end_idx]\n\u001b[0;32m     19\u001b[0m     pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(batch_keywords, cat\u001b[38;5;241m=\u001b[39mcat, \n\u001b[0;32m     20\u001b[0m                            timeframe\u001b[38;5;241m=\u001b[39mtimeframe,\n\u001b[0;32m     21\u001b[0m                            geo\u001b[38;5;241m=\u001b[39mgeo, \n\u001b[0;32m     22\u001b[0m                            gprop\u001b[38;5;241m=\u001b[39mgprop)\n\u001b[1;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     all_data\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m     27\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Google_Trends\\google_trend\\lib\\site-packages\\pytrends\\request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[0;32m    229\u001b[0m }\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[1;32md:\\Google_Trends\\google_trend\\lib\\site-packages\\pytrends\\request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[1;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[1;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "combined_data_dict = {}\n",
    "\n",
    "batch_size = 1\n",
    "for i in range(1, len(chunks) + 1):\n",
    "    chunks = globals()[f'chunks{i}']\n",
    "    combined_data_dict[f'combined_data{i}'] = fetch_trends_in_batches(chunks, \n",
    "                                                                      batch_size=batch_size, \n",
    "                                                                      cat=0, \n",
    "                                                                      timeframe='2004-01-01 2024-03-31', \n",
    "                                                                      geo='ZA', \n",
    "                                                                      gprop='')\n",
    "len(combined_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and stored the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of dataframes stored in combined_data_dict\n",
    "num_dataframes = len(combined_data_dict)\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the keys to access each dataframe\n",
    "for i in range(1, num_dataframes + 1):\n",
    "    key = f'combined_data{i}'\n",
    "    if key in combined_data_dict:\n",
    "        dataframes.append(combined_data_dict[key])\n",
    "\n",
    "# Concatenate the dataframes along the date index\n",
    "combined_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.str.endswith('isPartial')]\n",
    "\n",
    "# Reset index to make date index\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "# Drop duplicate date columns\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "# Set date column as index\n",
    "combined_df.set_index('date', inplace=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data to a CSV file\n",
    "combined_df.to_csv('data/gt_ZA_IBA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_trend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
