{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Google Trends data using capstone keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries/modules\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq(hl='en-US', tz=360, timeout=(40,25))\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the keyword dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('data/gdp_cat_queries_dict.json')\n",
    "cat_topics_dict = json.load(file1)\n",
    "cat_topics_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'569': ['cineplex', 'cinema'],\n",
       " '23': ['dance', 'theatre'],\n",
       " '47': ['honda', 'ford'],\n",
       " '815': ['ford', 'honda'],\n",
       " '170': ['license', 'driving'],\n",
       " '249': ['blue cross', 'desjardins'],\n",
       " '71': ['pizza pizza', 'pizza'],\n",
       " '276': ['restaurant', 'restaurants'],\n",
       " '634': ['clinic', 'dr'],\n",
       " '250': ['hospital', 'hopital'],\n",
       " '168': ['fire', 'emergency'],\n",
       " '437': ['depression', 'anxiety'],\n",
       " '11': ['home depot', 'ikea'],\n",
       " '29': ['mls', 'real estate'],\n",
       " '96': ['remax', 'real real'],\n",
       " '18': ['kijiji', 'walmart'],\n",
       " '67': ['hotel', 'air canada'],\n",
       " '179': ['hotel', 'hotels'],\n",
       " '5': ['google', 'apple'],\n",
       " '68': ['shoes', 'boots'],\n",
       " '78': ['xbox', 'videotron'],\n",
       " '696': ['or', 'bijoux'],\n",
       " '329': ['acces d', 'cra'],\n",
       " '95': ['staples', 'desk'],\n",
       " '423': ['bankruptcy', 'hollywoodpq'],\n",
       " '279': ['credit', 'mortgage'],\n",
       " '1160': ['business', 'pret'],\n",
       " '813': ['student', 'tuition'],\n",
       " '466': ['mortgage', 'calculator'],\n",
       " '468': ['lease', 'calculator'],\n",
       " '46': ['farm', 'plant'],\n",
       " '750': ['forest', 'forestry'],\n",
       " '747': ['salmon', 'fish'],\n",
       " '121': ['circulaire', 'iga'],\n",
       " '123': ['cigarettes', 'smoke'],\n",
       " '697': ['shoes', 'boots'],\n",
       " '1176': ['printing', 'vistaprint'],\n",
       " '1268': ['gas', 'gas prices'],\n",
       " '288': ['bottle depot', 'plastic'],\n",
       " '248': ['pharmacy', 'side effects'],\n",
       " '30': ['hp', 'kingston'],\n",
       " '287': ['generator', 'valve'],\n",
       " '612': ['oscar', 'car wash'],\n",
       " '13': ['google', 'mail'],\n",
       " '31': ['java', 'windows'],\n",
       " '7': ['rbc', 'td'],\n",
       " '38': ['insurance', 'desjardins'],\n",
       " '969': ['lawyer', 'law'],\n",
       " '477': ['architecture', 'architects'],\n",
       " '25': ['marketing', 'circulaire'],\n",
       " '380': ['vet', 'animal hospital'],\n",
       " '1010': ['vacations', 'voyage'],\n",
       " '726': ['acces', 'acces d'],\n",
       " '76': ['canada', 'passport'],\n",
       " '74': ['school', 'college'],\n",
       " '256': ['clinic', 'dr'],\n",
       " '508': ['chomage', 'assurance emploi'],\n",
       " '20': ['nhl', 'hockey'],\n",
       " '1199': ['ordre', 'abstract'],\n",
       " '144': ['hair removal', 'laser'],\n",
       " '748': ['tractor', 'deere'],\n",
       " '48': ['construction', 'doors'],\n",
       " '255': ['clinique', 'clinique m√©dicale'],\n",
       " '50': ['canada', 'tracking'],\n",
       " '664': ['logistics', 'distribution'],\n",
       " '60': ['jobs', 'job'],\n",
       " '802': ['jobs', 'developer'],\n",
       " '621': ['canning', 'kraft'],\n",
       " '1140': ['boat', 'kayak'],\n",
       " '841': ['superstore', 'walmart'],\n",
       " '289': ['trailers', 'trucks'],\n",
       " '665': ['ship', 'traversier'],\n",
       " '662': ['air', 'air france'],\n",
       " '354': ['canada', 'customs'],\n",
       " '666': ['rail', 'railway'],\n",
       " '1150': ['canada', 'tracking'],\n",
       " '277': ['beer', 'lcbo'],\n",
       " '650': ['doors', 'portail'],\n",
       " '651': ['bridge', 'pont'],\n",
       " '652': ['contractors', 'contracting'],\n",
       " '158': ['home depot', 'paint'],\n",
       " '1143': ['netflix', 'dvd'],\n",
       " '70': ['gift', 'birthday'],\n",
       " '271': ['vacuum', 'appliances'],\n",
       " '270': ['furniture', 'ikea'],\n",
       " '794': ['garmin', 'gps'],\n",
       " '233': ['hydro', 'gas'],\n",
       " '473': ['auto', 'cars'],\n",
       " '1339': ['carpool', 'ride'],\n",
       " '932': ['fifa', 'madden'],\n",
       " '882': ['dog', 'pet'],\n",
       " '94': ['yoga', 'fitness'],\n",
       " '293': ['wedding', 'bridal'],\n",
       " '205': ['car rental', 'taxi'],\n",
       " '208': ['niagara falls', 'toronto'],\n",
       " '1081': ['rentals', 'cottage'],\n",
       " '73': ['walmart', 'store'],\n",
       " '1188': ['garmin', 'gps'],\n",
       " '185': ['fashion', 'louis vuitton'],\n",
       " '610': ['truck', 'ford'],\n",
       " '206': ['cruise', 'cruises'],\n",
       " '1003': ['backpack', 'luggage'],\n",
       " '918': ['pizza pizza', 'pizza'],\n",
       " '355': ['livres', 'librairie'],\n",
       " '145': ['spa', 'massage'],\n",
       " '894': ['theatre', 'macbeth'],\n",
       " '960': ['emploi', 'quebec emploi'],\n",
       " '961': ['resume', 'cover letter'],\n",
       " '378': ['rent', 'for rent'],\n",
       " '465': ['insurance', 'home insurance'],\n",
       " '1164': ['survival', 'economist'],\n",
       " '784': ['finance', 'dow'],\n",
       " '1209': ['news', 'bbc'],\n",
       " '396': ['election', 'election results'],\n",
       " '408': ['toronto', 'news'],\n",
       " '832': ['flooring', 'carpet'],\n",
       " '952': ['pool', 'piscine'],\n",
       " '1139': ['td', 'monnex'],\n",
       " '107': ['stock', 'tsx'],\n",
       " '903': ['ttc', 'rrsp'],\n",
       " '343': ['sql', 'access'],\n",
       " '77': ['paypal', 'sql'],\n",
       " '278': ['tax', 'tva'],\n",
       " '1300': ['omnivox', 'cegep'],\n",
       " '730': ['git', 'github'],\n",
       " '341': ['salesforce', 'crm'],\n",
       " '334': ['expo', 'exhibition'],\n",
       " '314': ['security', 'avg'],\n",
       " '718': ['outsourcing', 'accenture'],\n",
       " '728': ['server', 'servers'],\n",
       " '1162': ['cra', 'cra login'],\n",
       " '53': ['godaddy', 'domain'],\n",
       " '342': ['erp', 'dashboard'],\n",
       " '1159': ['management', 'project'],\n",
       " '1214': ['trailers', 'trucks'],\n",
       " '670': ['homemade', 'potash'],\n",
       " '12': ['acces d', 'canada post'],\n",
       " '566': ['fabric fabric', 'fabric'],\n",
       " '672': ['glue', 'epoxy'],\n",
       " '673': ['couleur', 'couleurs'],\n",
       " '49': ['covid', 'manufacturing']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_topics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the keywords and create a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "keywords = [keyword for sublist in cat_topics_dict.values() for keyword in sublist]\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = list(set(keywords))\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the chunk size and split the list into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 15\n",
    "\n",
    "# Split the list into chunks\n",
    "chunks = [keywords[i:i + chunk_size] for i in range(0, len(keywords), chunk_size)]\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name each chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name each chunk as chunk_i starting from 1\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    globals()[f'chunks{i}'] = chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function fetches the Google Trend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_trends_in_batches(chunks,\n",
    "                            batch_size=1,\n",
    "                            cat=0, \n",
    "                            timeframe='2004-01-01 2024-03-31', \n",
    "                            geo='MU', \n",
    "                            gprop=''):\n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, timeout=(40, 25))\n",
    "    \n",
    "    all_data = []\n",
    "    num_batches = -(-len(chunks) // batch_size)  # Calculate number of batches\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        \n",
    "        batch_keywords = chunks[start_idx:end_idx]\n",
    "        \n",
    "        pytrends.build_payload(batch_keywords, cat=cat, \n",
    "                               timeframe=timeframe,\n",
    "                               geo=geo, \n",
    "                               gprop=gprop)\n",
    "        data = pytrends.interest_over_time()\n",
    "        \n",
    "        all_data.append(data)\n",
    "\n",
    "    combined_data = pd.concat(all_data, axis=1)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store combined dataframes in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_dict = {}\n",
    "\n",
    "batch_size = 1\n",
    "for i in range(1, len(chunks) + 1):\n",
    "    chunks = globals()[f'chunks{i}']\n",
    "    combined_data_dict[f'combined_data{i}'] = fetch_trends_in_batches(chunks, \n",
    "                                                                      batch_size=batch_size, \n",
    "                                                                      cat=0, \n",
    "                                                                      timeframe='2004-01-01 2024-03-31', \n",
    "                                                                      geo='MU', \n",
    "                                                                      gprop='')\n",
    "    len(combined_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and stored the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depression</th>\n",
       "      <th>construction</th>\n",
       "      <th>fashion</th>\n",
       "      <th>jobs</th>\n",
       "      <th>bbc</th>\n",
       "      <th>domain</th>\n",
       "      <th>avg</th>\n",
       "      <th>forest</th>\n",
       "      <th>pizza pizza</th>\n",
       "      <th>hotels</th>\n",
       "      <th>...</th>\n",
       "      <th>college</th>\n",
       "      <th>covid</th>\n",
       "      <th>developer</th>\n",
       "      <th>distribution</th>\n",
       "      <th>real estate</th>\n",
       "      <th>portail</th>\n",
       "      <th>dashboard</th>\n",
       "      <th>election results</th>\n",
       "      <th>appliances</th>\n",
       "      <th>architecture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-05-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows √ó 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            depression  construction  fashion  jobs  bbc  domain  avg  forest  \\\n",
       "date                                                                            \n",
       "2004-01-01           0             0        0   100    0       0    0       0   \n",
       "2004-02-01           0             0        0     0    0       0    0       0   \n",
       "2004-03-01           0             0        0     0    0       0    0       0   \n",
       "2004-04-01           0             0        0     0    0       0    0       0   \n",
       "2004-05-01           0             0        0     0    0       0    0       0   \n",
       "...                ...           ...      ...   ...  ...     ...  ...     ...   \n",
       "2023-11-01           3            16       17    16   48      23    0      44   \n",
       "2023-12-01           3            15       18    16   48      18    0      80   \n",
       "2024-01-01           4            15       12    19   45      14    0      54   \n",
       "2024-02-01           3            20       12    21   36      22    0      76   \n",
       "2024-03-01           3            20       13    16   36      17    0      67   \n",
       "\n",
       "            pizza pizza  hotels  ...  college  covid  developer  distribution  \\\n",
       "date                             ...                                            \n",
       "2004-01-01            0       0  ...        0      0          0             0   \n",
       "2004-02-01            0       0  ...        0     70          0             0   \n",
       "2004-03-01            0       0  ...        0      0          0             0   \n",
       "2004-04-01            0       0  ...        0      0          0             0   \n",
       "2004-05-01            0       0  ...        0      0          0             0   \n",
       "...                 ...     ...  ...      ...    ...        ...           ...   \n",
       "2023-11-01           73      12  ...       17      3          8             8   \n",
       "2023-12-01           87      10  ...       27      6         14             6   \n",
       "2024-01-01           70       9  ...       30      3         18             7   \n",
       "2024-02-01           73      10  ...       27      2         19             7   \n",
       "2024-03-01           73       9  ...       22      2         13             9   \n",
       "\n",
       "            real estate  portail  dashboard  election results  appliances  \\\n",
       "date                                                                        \n",
       "2004-01-01            0        0          0                 0           0   \n",
       "2004-02-01            0        0          0                 0           0   \n",
       "2004-03-01            0        0          0                 0           0   \n",
       "2004-04-01            0        0          0                 0           0   \n",
       "2004-05-01            0        0          0                 0           0   \n",
       "...                 ...      ...        ...               ...         ...   \n",
       "2023-11-01           25        6         74                 0          45   \n",
       "2023-12-01           33        6         75                 2           0   \n",
       "2024-01-01           33        7         70                 0          42   \n",
       "2024-02-01           30        6         84                 1           0   \n",
       "2024-03-01           38        4         89                 1          40   \n",
       "\n",
       "            architecture  \n",
       "date                      \n",
       "2004-01-01             0  \n",
       "2004-02-01             0  \n",
       "2004-03-01             0  \n",
       "2004-04-01             0  \n",
       "2004-05-01             0  \n",
       "...                  ...  \n",
       "2023-11-01            24  \n",
       "2023-12-01            15  \n",
       "2024-01-01            25  \n",
       "2024-02-01            30  \n",
       "2024-03-01            28  \n",
       "\n",
       "[243 rows x 216 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of dataframes stored in combined_data_dict\n",
    "num_dataframes = len(combined_data_dict)\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the keys to access each dataframe\n",
    "for i in range(1, num_dataframes + 1):\n",
    "    key = f'combined_data{i}'\n",
    "    if key in combined_data_dict:\n",
    "        dataframes.append(combined_data_dict[key])\n",
    "\n",
    "# Concatenate the dataframes along the date index\n",
    "combined_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.str.endswith('isPartial')]\n",
    "\n",
    "# Reset index to make date index\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "# Drop duplicate date columns\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "# Set date column as index\n",
    "combined_df.set_index('date', inplace=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data to a CSV file\n",
    "combined_df.to_csv('data/gt_MU_capstone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_trend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
